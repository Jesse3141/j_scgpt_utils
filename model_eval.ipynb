{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.469892746Z",
     "start_time": "2023-11-29T11:17:18.171473763Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from fastai.vision.all import *\n",
    "import torch\n",
    "from fastai.layers import Lambda\n",
    "from fastai.tabular.all import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import socket\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.574265434Z",
     "start_time": "2023-11-29T11:17:18.180573033Z"
    }
   },
   "outputs": [],
   "source": [
    "# globlas\n",
    "#print computer name:\n",
    "comp_name = str(socket.gethostname())\n",
    "base_path = str('')\n",
    "if (comp_name == 'shairlab.upper.2080'):\n",
    "    base_dir = Path('/home/jesse/lab/trans_stamp/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.574611310Z",
     "start_time": "2023-11-29T11:17:18.225957400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jesse/lab/trans_stamp/scgpt/jesse_utils\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.574705093Z",
     "start_time": "2023-11-29T11:17:18.226196632Z"
    }
   },
   "outputs": [],
   "source": [
    "#function for running analysis\n",
    "def regression_baseline(genexp, y_col, non_score_cols):\n",
    "    '''\n",
    "\n",
    "    :param genexp: a df of genexp\n",
    "    :param y_col: the name of the label col\n",
    "    :param non_score_cols: name of cols to drop for X as a list\n",
    "    :return: nome\n",
    "    '''\n",
    "\n",
    "\n",
    "    # Preprocess the data (Assuming 'label' is your target variable)\n",
    "    X = genexp .drop(non_score_cols, axis=1)\n",
    "    y = genexp [y_col]\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    # Train Random Forest\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and Evaluation for Random Forest\n",
    "    rf_predictions = rf.predict(X_test)\n",
    "    print('random forests:\\n',classification_report(y_test, rf_predictions))\n",
    "\n",
    "\n",
    "    # Train Elastic Net\n",
    "    en = ElasticNet()\n",
    "    en.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and Evaluation for Elastic Net\n",
    "    # Note: Elastic Net is a regression model; you might need to convert its predictions to a binary format for classification\n",
    "    en_predictions = en.predict(X_test)\n",
    "    en_predictions = [1 if p > 0.5 else 0 for p in en_predictions]  # Example threshold\n",
    "    print('elsatic net:\\n',classification_report(y_test, en_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.574770623Z",
     "start_time": "2023-11-29T11:17:18.226363109Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_sample_weights(target_data):\n",
    "    class_sample_counts = target_data.value_counts()\n",
    "    weight = 1. / class_sample_counts\n",
    "    samples_weight = weight[target_data].values\n",
    "    return torch.DoubleTensor(samples_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.574877144Z",
     "start_time": "2023-11-29T11:17:18.226491272Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dls(data,scale=True,scale_cols =2, regression = False, weighted = True):\n",
    "    \n",
    "    #apply scaling\n",
    "    if scale:\n",
    "        scaler = RobustScaler()\n",
    "        data[data.columns[scale_cols:]] = scaler.fit_transform(data[data.columns[scale_cols:]])\n",
    "\n",
    "    #get name of cols\n",
    "    #find col with 'labal'\n",
    "    label_col = [col for col in data.columns if 'label' in col]\n",
    "    #print warning if more than one label col\n",
    "    if len(label_col) > 1:\n",
    "        print('more than one label col')\n",
    "        print(label_col)\n",
    "        print('using first label col')\n",
    "        label_col = label_col[0]\n",
    "    else:\n",
    "        label_col = label_col[0]\n",
    "\n",
    "    #get metadata cols: cols with label or sample_id\n",
    "    metadata_cols = [col for col in data.columns if 'label' in col or 'Sample' in col]\n",
    "\n",
    "    #print regression baseline:\n",
    "    if regression:\n",
    "        regression_baseline(data, label_col, metadata_cols)\n",
    "\n",
    "    \n",
    "    #create data loaders\n",
    "\n",
    "    # Preprocess the data (Assuming 'label' is your target variable)\n",
    "    #split scgpt_df into val and train\n",
    "    train_df = data.sample(frac=0.8,random_state=200) #random state is a seed value\n",
    "    val_df = data.drop(train_df.index)\n",
    "\n",
    "    # create stacked tensor of sample vectors. each row is a sample, each col is a dim\n",
    "    train_x = train_df.drop(metadata_cols, axis=1)\n",
    "    train_x = torch.stack([tensor(row) for row in train_x.values], dim=0)\n",
    "    train_y = tensor(train_df[label_col].values).float()\n",
    "    \n",
    "    val_x = val_df.drop(metadata_cols, axis=1)\n",
    "    val_x = torch.stack([tensor(row) for row in val_x.values], dim =0)\n",
    "    val_y = tensor(val_df[label_col].values).float()\n",
    "\n",
    "    #create data sets from train and val x and y\n",
    "    train_dset = list(zip(train_x,train_y))\n",
    "    val_dset = list(zip(val_x,val_y))\n",
    "    \n",
    "    #create weighted sampler\n",
    "    if weighted:\n",
    "        train_sample_weights = create_sample_weights(train_df[label_col])\n",
    "        train_sampler = WeightedRandomSampler(train_sample_weights, len(train_sample_weights))\n",
    "        dl_train = DataLoader(train_dset, batch_size=64, sampler=train_sampler)\n",
    "    #if not weighted, create dl without sampler\n",
    "    if not weighted:\n",
    "        dl_train = DataLoader(train_dset, batch_size=64)\n",
    "    \n",
    "    #create data loaders\n",
    "    dl_val = DataLoader(val_dset, batch_size=64)\n",
    "\n",
    "    #return dls\n",
    "    return (dl_train, dl_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# create a simple neural net\n",
    "\n",
    "now that we've fixed the gradiants and have proper learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.577122171Z",
     "start_time": "2023-11-29T11:17:18.238573354Z"
    }
   },
   "outputs": [],
   "source": [
    "def stamp_loss(preds, targs):\n",
    "    preds = preds.sigmoid()\n",
    "    return torch.where(targs==1, 1-preds, preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.577224634Z",
     "start_time": "2023-11-29T11:17:18.281951191Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.577336580Z",
     "start_time": "2023-11-29T11:17:18.282198183Z"
    }
   },
   "outputs": [],
   "source": [
    "def first_nn(input_dim):\n",
    "    nn_model = nn.Sequential(\n",
    "    nn.Linear(input_dim, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 1),\n",
    "    Lambda(lambda x: x.squeeze(-1))\n",
    "    )\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:18:50.187200158Z",
     "start_time": "2023-11-29T11:18:50.103606630Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_nn(dl_train, dl_val, input_dim, epochs = 10, lr =0.1, find_lr = False, report = True):\n",
    "    #having creted dataloadrs from data sets for train and cal, create a dls \n",
    "    dls = DataLoaders(dl_train, dl_val)\n",
    "\n",
    "    model = first_nn(input_dim)\n",
    "    \n",
    "    #optimisers: Adam, AdamW, RMSProp, SGD\n",
    "    #loss:nn.CrossEntropyLoss, nn.BCEWithLogitsLoss,\n",
    "    # nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    # Create your learner\n",
    "    learn = Learner(dls, model, opt_func = Adam, loss_func=SGD, metrics=error_rate)\n",
    "\n",
    "    #find suggested lr\n",
    "    if find_lr:\n",
    "        lr_suggestion = learn.lr_find()\n",
    "        # Accessing the suggested learning rate\n",
    "        lr = lr_suggestion.lr_min\n",
    "    #train\n",
    "    learn.fit(epochs, lr)\n",
    "\n",
    "    # create classification report\n",
    "    if report:\n",
    "        '''# Get predictions\n",
    "        preds, targets = learn.get_preds(dl=dls.valid)\n",
    "        predictions = preds.argmax(dim=1)\n",
    "    \n",
    "        # Convert tensors to numpy arrays for compatibility with scikit-learn\n",
    "        predictions_np = predictions.numpy()\n",
    "        targets_np = targets.numpy()\n",
    "    \n",
    "        # Generate classification report\n",
    "        print('Neural Network:\\n', classification_report(targets_np, predictions_np))'''\n",
    "        interp = ClassificationInterpretation.from_learner(learn)\n",
    "        interp.plot_confusion_matrix()\n",
    "        plt.show()\n",
    "        # Get top losses\n",
    "        top_losses = interp.top_losses()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.577659736Z",
     "start_time": "2023-11-29T11:17:18.325818665Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# load, examine and normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.577877818Z",
     "start_time": "2023-11-29T11:17:18.326049830Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_path =Path(base_dir / 'scgpt/data/scgpt_embeddings/brca_sub_scgpt_emb.csv') \n",
    "scgpt_df = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:18.630428235Z",
     "start_time": "2023-11-29T11:17:18.401203176Z"
    }
   },
   "outputs": [],
   "source": [
    "# load raw genexp data\n",
    "raw_genxp_path = Path(base_dir / 'scgpt/data/bulk_brca_erbb2/brca_ERBB2_genexp_oncosig_labels_gene_map.csv') \n",
    "raw_genexp = pd.read_csv(raw_genxp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T11:17:20.872544031Z",
     "start_time": "2023-11-29T11:17:20.633218495Z"
    }
   },
   "outputs": [],
   "source": [
    "data = raw_genexp\n",
    "\n",
    "#get dls\n",
    "dl_train, dl_val = create_dls(data, weighted = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T11:06:38.194969407Z",
     "start_time": "2023-11-29T11:06:38.193865003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_x shape: torch.Size([64, 855])\n",
      "Train_y shape: torch.Size([64])\n",
      "Output shape: torch.Size([64])\n",
      "Train_y data type: torch.float32\n",
      "Loss: tensor(0.7101, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#trouble shoot dim problem with training\n",
    "\n",
    "# Example check before the training loop\n",
    "train_x, train_y = next(iter(dl_train))  # Fetch a batch from the training DataLoader\n",
    "\n",
    "# Check shapes\n",
    "print(\"Train_x shape:\", train_x.shape)\n",
    "print(\"Train_y shape:\", train_y.shape)\n",
    "\n",
    "# Assuming you have defined 'first_nn'\n",
    "input_dim = 855  # Set this to the correct input dimension\n",
    "model = first_nn(input_dim)\n",
    "\n",
    "# Create a sample input tensor with the correct shape\n",
    "# For example, if your input data is a vector per sample, you can create a dummy batch like this:\n",
    "# Use a batch of data instead of a single sample\n",
    "batch_input = torch.randn(64, input_dim)  # Mock batch with 64 samples\n",
    "\n",
    "# Pass the sample input through the model\n",
    "# Adjust the shape of the model's output\n",
    "output = model(train_x)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "# Check data types\n",
    "print(\"Train_y data type:\", train_y.dtype)\n",
    "\n",
    "\n",
    "# If using BCEWithLogitsLoss\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "loss = loss_func(output, train_y.float())  # Convert labels to float\n",
    "print(\"Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:18:53.806880590Z",
     "start_time": "2023-11-29T11:18:53.674497303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Trying to set 64 values for lr but there are 1 parameter groups.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Usage\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mrun_nn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdl_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdl_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m855\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfind_lr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreport\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[35], line 20\u001B[0m, in \u001B[0;36mrun_nn\u001B[0;34m(dl_train, dl_val, input_dim, epochs, lr, find_lr, report)\u001B[0m\n\u001B[1;32m     18\u001B[0m     lr \u001B[38;5;241m=\u001B[39m lr_suggestion\u001B[38;5;241m.\u001B[39mlr_min\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m#train\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m \u001B[43mlearn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# create classification report\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m report:\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/learner.py:264\u001B[0m, in \u001B[0;36mLearner.fit\u001B[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mset_hypers(lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr \u001B[38;5;28;01mif\u001B[39;00m lr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m lr)\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_epoch \u001B[38;5;241m=\u001B[39m n_epoch\n\u001B[0;32m--> 264\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_with_events\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_fit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfit\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCancelFitException\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_end_cleanup\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/learner.py:199\u001B[0m, in \u001B[0;36mLearner._with_events\u001B[0;34m(self, f, event_type, ex, final)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_with_events\u001B[39m(\u001B[38;5;28mself\u001B[39m, f, event_type, ex, final\u001B[38;5;241m=\u001B[39mnoop):\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m: \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbefore_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m);  \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ex: \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter_cancel_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m);  final()\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/learner.py:253\u001B[0m, in \u001B[0;36mLearner._do_fit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_epoch):\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepoch\u001B[38;5;241m=\u001B[39mepoch\n\u001B[0;32m--> 253\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_with_events\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mepoch\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCancelEpochException\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/learner.py:199\u001B[0m, in \u001B[0;36mLearner._with_events\u001B[0;34m(self, f, event_type, ex, final)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_with_events\u001B[39m(\u001B[38;5;28mself\u001B[39m, f, event_type, ex, final\u001B[38;5;241m=\u001B[39mnoop):\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m: \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbefore_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m);  \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ex: \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter_cancel_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m);  final()\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/learner.py:247\u001B[0m, in \u001B[0;36mLearner._do_epoch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_do_epoch\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 247\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_epoch_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_epoch_validate()\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/learner.py:239\u001B[0m, in \u001B[0;36mLearner._do_epoch_train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_do_epoch_train\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdl \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdls\u001B[38;5;241m.\u001B[39mtrain\n\u001B[0;32m--> 239\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_with_events\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mall_batches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCancelTrainException\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/learner.py:199\u001B[0m, in \u001B[0;36mLearner._with_events\u001B[0;34m(self, f, event_type, ex, final)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_with_events\u001B[39m(\u001B[38;5;28mself\u001B[39m, f, event_type, ex, final\u001B[38;5;241m=\u001B[39mnoop):\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m: \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbefore_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m);  \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ex: \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter_cancel_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m);  final()\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/learner.py:205\u001B[0m, in \u001B[0;36mLearner.all_batches\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mall_batches\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdl)\n\u001B[0;32m--> 205\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m o \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdl): \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mone_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mo\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/learner.py:235\u001B[0m, in \u001B[0;36mLearner.one_batch\u001B[0;34m(self, i, b)\u001B[0m\n\u001B[1;32m    233\u001B[0m b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_device(b)\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_split(b)\n\u001B[0;32m--> 235\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_with_events\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_one_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbatch\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCancelBatchException\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/learner.py:199\u001B[0m, in \u001B[0;36mLearner._with_events\u001B[0;34m(self, f, event_type, ex, final)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_with_events\u001B[39m(\u001B[38;5;28mself\u001B[39m, f, event_type, ex, final\u001B[38;5;241m=\u001B[39mnoop):\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m: \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbefore_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m);  \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ex: \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter_cancel_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m);  final()\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/learner.py:219\u001B[0m, in \u001B[0;36mLearner._do_one_batch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter_pred\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    218\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39myb):\n\u001B[0;32m--> 219\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43myb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_grad\u001B[38;5;241m.\u001B[39mclone()\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28mself\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter_loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/optimizer.py:184\u001B[0m, in \u001B[0;36mSGD\u001B[0;34m(params, lr, mom, wd, decouple_wd)\u001B[0m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mom \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m: cbs\u001B[38;5;241m.\u001B[39mappend(average_grad)\n\u001B[1;32m    183\u001B[0m cbs\u001B[38;5;241m.\u001B[39mappend(sgd_step \u001B[38;5;28;01mif\u001B[39;00m mom\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m momentum_step)\n\u001B[0;32m--> 184\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mOptimizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcbs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmom\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwd\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/optimizer.py:100\u001B[0m, in \u001B[0;36mOptimizer.__init__\u001B[0;34m(self, params, cbs, **defaults)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_lists \u001B[38;5;241m=\u001B[39m L(L(p) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m params) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(params[\u001B[38;5;241m0\u001B[39m], (L,\u001B[38;5;28mlist\u001B[39m)) \u001B[38;5;28;01melse\u001B[39;00m L([params])\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhypers \u001B[38;5;241m=\u001B[39m L({} \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m range_of(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_lists))\n\u001B[0;32m--> 100\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_hypers\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdefaults\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfrozen_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/optimizer.py:44\u001B[0m, in \u001B[0;36m_BaseOptimizer.set_hypers\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m---> 44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_hypers\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs): \u001B[43mL\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstarmap\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_hyper\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastcore/foundation.py:180\u001B[0m, in \u001B[0;36mL.starmap\u001B[0;34m(self, f, *args, **kwargs)\u001B[0m\n\u001B[0;32m--> 180\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstarmap\u001B[39m(\u001B[38;5;28mself\u001B[39m, f, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs): \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_new\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitertools\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstarmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastcore/foundation.py:111\u001B[0m, in \u001B[0;36mL._new\u001B[0;34m(self, items, *args, **kwargs)\u001B[0m\n\u001B[0;32m--> 111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_new\u001B[39m(\u001B[38;5;28mself\u001B[39m, items, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs): \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastcore/foundation.py:98\u001B[0m, in \u001B[0;36m_L_Meta.__call__\u001B[0;34m(cls, x, *args, **kwargs)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mcls\u001B[39m, x\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x,\u001B[38;5;28mcls\u001B[39m): \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[0;32m---> 98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastcore/foundation.py:106\u001B[0m, in \u001B[0;36mL.__init__\u001B[0;34m(self, items, use_list, match, *rest)\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, items\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39mrest, use_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, match\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (use_list \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_array(items):\n\u001B[0;32m--> 106\u001B[0m         items \u001B[38;5;241m=\u001B[39m \u001B[43mlistify\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(items)\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastcore/basics.py:66\u001B[0m, in \u001B[0;36mlistify\u001B[0;34m(o, use_list, match, *rest)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(o, \u001B[38;5;28mlist\u001B[39m): res \u001B[38;5;241m=\u001B[39m o\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(o, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m is_array(o): res \u001B[38;5;241m=\u001B[39m [o]\n\u001B[0;32m---> 66\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_iter(o): res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m: res \u001B[38;5;241m=\u001B[39m [o]\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m match \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/mambaforge/envs/fastai_env/lib/python3.10/site-packages/fastai/optimizer.py:59\u001B[0m, in \u001B[0;36m_BaseOptimizer.set_hyper\u001B[0;34m(self, k, v)\u001B[0m\n\u001B[1;32m     57\u001B[0m v \u001B[38;5;241m=\u001B[39m L(v, use_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(v)\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m1\u001B[39m: v \u001B[38;5;241m=\u001B[39m v\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_lists)\n\u001B[0;32m---> 59\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(v) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhypers), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrying to set \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(v)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m values for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m but there are \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_lists)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m parameter groups.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_hyper(k, v)\n",
      "\u001B[0;31mAssertionError\u001B[0m: Trying to set 64 values for lr but there are 1 parameter groups."
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "run_nn(dl_train, dl_val, input_dim=855, epochs=10, lr=0.1, find_lr=False, report = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# old dev cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Assuming 'dls' is your DataLoaders object and 'train' is the training DataLoader\n",
    "batch = dls.train.one_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:14:39.609898503Z",
     "start_time": "2023-11-29T08:14:39.557845058Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of entire DataFrame: 8.752375429106664\n",
      "Standard Deviation of entire DataFrame: 3.019593388750879\n"
     ]
    }
   ],
   "source": [
    "#check data variation. each row is a sample, each col is a dim\n",
    "curr_data =data\n",
    "value_df = curr_data.drop(['Sample_ID','oncosig_label_ERBB2'], axis=1)\n",
    "# Flatten the DataFrame to a single series and calculate mean and std\n",
    "all_values = value_df.values.flatten()\n",
    "overall_mean = all_values.mean()\n",
    "overall_std = all_values.std()\n",
    "\n",
    "print(f\"Mean of entire DataFrame: {overall_mean}\")\n",
    "print(f\"Standard Deviation of entire DataFrame: {overall_std}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:15:28.825902453Z",
     "start_time": "2023-11-29T08:15:28.769219146Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get name of cols\n",
    "#find col with 'labal'\n",
    "label_col = [col for col in curr_data.columns if 'label' in col]\n",
    "#print warning if more than one label col\n",
    "if len(label_col) > 1:\n",
    "    print('more than one label col')\n",
    "    print(label_col)\n",
    "    print('using first label col')\n",
    "    label_col = label_col[0]\n",
    "else:\n",
    "    label_col = label_col[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:15:44.032940293Z",
     "start_time": "2023-11-29T08:15:43.987537371Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get metadata cols: cols with label or sample_id\n",
    "metadata_cols = [col for col in curr_data.columns if 'label' in col or 'Sample' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:14:27.613317202Z",
     "start_time": "2023-11-29T08:14:27.434198323Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# examine data mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# create Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:16:29.264446654Z",
     "start_time": "2023-11-29T08:16:29.213095147Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess the data (Assuming 'label' is your target variable)\n",
    "#split scgpt_df into val and train\n",
    "train_df = curr_data.sample(frac=0.8,random_state=200) #random state is a seed value\n",
    "val_df = curr_data.drop(train_df.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T13:46:14.369642404Z",
     "start_time": "2023-11-28T13:46:14.314091142Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:16:36.762395464Z",
     "start_time": "2023-11-29T08:16:36.735263517Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARD3     9.5088\n",
      "SPP1      12.7887\n",
      "DST       11.2423\n",
      "DCDC2      5.4384\n",
      "ERBB3     11.7830\n",
      "ERBB4      9.1595\n",
      "GJB2      10.8425\n",
      "KIF18A     6.2226\n",
      "KIF18B     6.4233\n",
      "4-Mar      5.9467\n",
      "STYK1      6.7230\n",
      "CDKN2B     9.4294\n",
      "Name: 776, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([759, 855])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create stacked tensor of sample vectors. each row is a sample, each col is a dim\n",
    "train_x = train_df.drop(metadata_cols, axis=1)\n",
    "print(train_x.iloc[0,500:512])\n",
    "# Convert each row of the DataFrame to a tensor and stack them\n",
    "train_x = torch.stack([tensor(row) for row in train_x.values], dim=0)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:18:25.868522980Z",
     "start_time": "2023-11-29T08:18:25.811408719Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.2387,  0.4856, -0.2119, -0.1877, -0.9208, -0.0629,  0.7216, -0.5838, -0.5149,  1.9146,  0.1509,  0.5064]),\n",
       " torch.Size([759, 855]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0,500:512],train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:18:29.554050759Z",
     "start_time": "2023-11-29T08:18:29.539382778Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([759]), tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor(train_df[label_col].values)\n",
    "train_y.shape,train_y[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:18:31.270768875Z",
     "start_time": "2023-11-29T08:18:31.250129598Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([190]), tensor(0), torch.Size([190, 855]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x = val_df.drop(metadata_cols, axis=1)\n",
    "val_x = torch.stack([tensor(row) for row in val_x.values], dim =0)\n",
    "\n",
    "val_y = tensor(val_df[label_col].values)\n",
    "val_y.shape,val_y[0],val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T13:46:14.478150987Z",
     "start_time": "2023-11-28T13:46:14.391271929Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:18:32.940052174Z",
     "start_time": "2023-11-29T08:18:32.921431841Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create data sets from train and val x and y\n",
    "train_dset = list(zip(train_x,train_y))\n",
    "val_dset = list(zip(val_x,val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data loaders\n",
    "dl_train = DataLoader(train_dset, batch_size=64)\n",
    "dl_val = DataLoader(val_dset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#examine the the first few rows and cols\n",
    "print(data.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# manual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:18:45.174165764Z",
     "start_time": "2023-11-29T08:18:45.152862092Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stamp_loss(preds, targs):\n",
    "    preds = preds.sigmoid()\n",
    "    return torch.where(targs==1, 1-preds, preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:18:35.248177865Z",
     "start_time": "2023-11-29T08:18:35.224764505Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:20:15.640770842Z",
     "start_time": "2023-11-29T08:20:15.574201858Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init weights\n",
    "weights_1 = init_params(855,1)\n",
    "\n",
    "\n",
    "bias_1 = init_params(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:18:47.378373412Z",
     "start_time": "2023-11-29T08:18:47.353102957Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([855]), tensor(0))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x,y= train_dset[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:18:43.258784643Z",
     "start_time": "2023-11-29T08:18:43.243147105Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#simple linear layer\n",
    "\n",
    "def linear1(xb): return xb@weights_1 + bias_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:18:49.672043216Z",
     "start_time": "2023-11-29T08:18:49.659307910Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 855]), torch.Size([64]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xb,yb = first(dl_train)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T13:46:14.536899071Z",
     "start_time": "2023-11-28T13:46:14.478097664Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test mini batch\n",
    "batch = train_x[:100]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = linear1(batch)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T13:46:14.678324438Z",
     "start_time": "2023-11-28T13:46:14.489635955Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5076, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = stamp_loss(preds, train_y[:100])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for each sample in batch (tensor of 100 x 512) create a tensor of mean and sd, and then plot\n",
    "batch_means = batch.mean(dim=1)\n",
    "batch_stds = batch.std(dim=1)\n",
    "#create hist of mean\n",
    "plt.hist(batch_means.cpu().numpy(), bins=20)\n",
    "plt.show()\n",
    "plt.hist(batch_stds.cpu().numpy(), bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T13:46:15.048258968Z",
     "start_time": "2023-11-28T13:46:15.016676443Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512]),\n",
       " tensor(1.4028e-05),\n",
       " tensor([0.1365]),\n",
       " tensor([-2.4886e-02,  1.4720e-02,  2.4593e-02,  2.0982e-02,  5.7275e-02,  3.2034e-02,  1.9298e-02,  4.5949e-02, -5.9231e-02,  9.0581e-05,  4.3937e-02, -4.5054e-03,  4.8138e-03,  8.5608e-03,\n",
       "         -3.6844e-02, -6.6057e-02,  3.2865e-02,  2.8748e-02, -8.5472e-03,  9.2744e-03]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get grad\n",
    "loss.backward()\n",
    "weights_1.grad.shape, weights_1.grad.mean(), bias_1.grad, weights_1.grad[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:18:59.145194375Z",
     "start_time": "2023-11-29T08:18:59.116624498Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = stamp_loss(preds, yb)\n",
    "    loss.backward()\n",
    "    #print stat of grad: mean weights grad and 0:5 of weights grad\n",
    "    print('mean grad:\\n', weights_1.grad.mean(),'\\n first 5 grad', weights_1.grad[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:19:02.797361132Z",
     "start_time": "2023-11-29T08:19:02.778411855Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in dl_train:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            #print first 5 weights\n",
    "            #print('params:\\n', p.data[:5])\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:19:04.308983695Z",
     "start_time": "2023-11-29T08:19:04.308387052Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T13:46:15.269708930Z",
     "start_time": "2023-11-28T13:46:15.074112678Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4800)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch), train_y[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:19:06.044686445Z",
     "start_time": "2023-11-29T08:19:06.031565047Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in dl_val]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:20:28.603999629Z",
     "start_time": "2023-11-29T08:20:27.583800729Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean grad:\n",
      " tensor(0.0001) \n",
      " first 5 grad tensor([0.0070, 0.0000, 0.0074, 0.0009, 0.0056])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([ 0.0059,  0.0000, -0.0007,  0.0022, -0.0048])\n",
      "mean grad:\n",
      " tensor(-0.0031) \n",
      " first 5 grad tensor([ 0.0095,  0.0000, -0.0082, -0.0065,  0.0017])\n",
      "mean grad:\n",
      " tensor(0.0020) \n",
      " first 5 grad tensor([0.0032, 0.0000, 0.0061, 0.0007, 0.0031])\n",
      "mean grad:\n",
      " tensor(0.0003) \n",
      " first 5 grad tensor([-0.0029,  0.0000,  0.0057, -0.0052, -0.0062])\n",
      "mean grad:\n",
      " tensor(0.0003) \n",
      " first 5 grad tensor([0.0011, 0.0000, 0.0020, 0.0014, 0.0067])\n",
      "mean grad:\n",
      " tensor(-7.0838e-05) \n",
      " first 5 grad tensor([-0.0023,  0.0000, -0.0003, -0.0011,  0.0013])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([-0.0024,  0.0000, -0.0077, -0.0003, -0.0025])\n",
      "mean grad:\n",
      " tensor(-0.0015) \n",
      " first 5 grad tensor([ 0.0008,  0.0000, -0.0059, -0.0020, -0.0056])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([ 0.0143,  0.0000, -0.0026,  0.0080,  0.0052])\n",
      "mean grad:\n",
      " tensor(0.0010) \n",
      " first 5 grad tensor([-0.0015,  0.0000,  0.0040,  0.0007,  0.0022])\n",
      "mean grad:\n",
      " tensor(-0.0012) \n",
      " first 5 grad tensor([0.0112, 0.0000, 0.0058, 0.0077, 0.0059])\n",
      "0.4635 mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([8.7112e-03, 0.0000e+00, 5.6944e-03, 5.5294e-05, 4.9586e-03])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([ 0.0057,  0.0000, -0.0011,  0.0020, -0.0047])\n",
      "mean grad:\n",
      " tensor(-0.0031) \n",
      " first 5 grad tensor([ 0.0091,  0.0000, -0.0083, -0.0085, -0.0005])\n",
      "mean grad:\n",
      " tensor(0.0020) \n",
      " first 5 grad tensor([0.0034, 0.0000, 0.0062, 0.0009, 0.0030])\n",
      "mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([-0.0027,  0.0000,  0.0050, -0.0039, -0.0042])\n",
      "mean grad:\n",
      " tensor(0.0002) \n",
      " first 5 grad tensor([0.0018, 0.0000, 0.0022, 0.0005, 0.0077])\n",
      "mean grad:\n",
      " tensor(-5.8044e-05) \n",
      " first 5 grad tensor([-0.0025,  0.0000, -0.0002, -0.0012,  0.0018])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([-0.0022,  0.0000, -0.0074,  0.0002, -0.0020])\n",
      "mean grad:\n",
      " tensor(-0.0014) \n",
      " first 5 grad tensor([ 0.0013,  0.0000, -0.0061, -0.0009, -0.0048])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0129,  0.0000, -0.0030,  0.0073,  0.0047])\n",
      "mean grad:\n",
      " tensor(0.0010) \n",
      " first 5 grad tensor([7.1290e-05, 0.0000e+00, 4.5545e-03, 1.7435e-04, 1.8517e-03])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([ 0.0068,  0.0000,  0.0019,  0.0052, -0.0008])\n",
      "0.4635 mean grad:\n",
      " tensor(-0.0004) \n",
      " first 5 grad tensor([ 0.0100,  0.0000,  0.0045, -0.0013,  0.0046])\n",
      "mean grad:\n",
      " tensor(-0.0004) \n",
      " first 5 grad tensor([ 0.0054,  0.0000, -0.0014,  0.0013, -0.0049])\n",
      "mean grad:\n",
      " tensor(-0.0029) \n",
      " first 5 grad tensor([ 0.0088,  0.0000, -0.0083, -0.0109, -0.0043])\n",
      "mean grad:\n",
      " tensor(0.0019) \n",
      " first 5 grad tensor([0.0035, 0.0000, 0.0058, 0.0011, 0.0028])\n",
      "mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([-0.0023,  0.0000,  0.0044, -0.0028, -0.0025])\n",
      "mean grad:\n",
      " tensor(1.7828e-05) \n",
      " first 5 grad tensor([ 0.0031,  0.0000,  0.0023, -0.0012,  0.0094])\n",
      "mean grad:\n",
      " tensor(-7.3614e-05) \n",
      " first 5 grad tensor([-2.8423e-03,  0.0000e+00, -3.4963e-05, -1.5581e-03,  2.1243e-03])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([-0.0020,  0.0000, -0.0072,  0.0005, -0.0016])\n",
      "mean grad:\n",
      " tensor(-0.0011) \n",
      " first 5 grad tensor([ 0.0024,  0.0000, -0.0059,  0.0010, -0.0034])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0119,  0.0000, -0.0031,  0.0070,  0.0046])\n",
      "mean grad:\n",
      " tensor(0.0011) \n",
      " first 5 grad tensor([ 0.0023,  0.0000,  0.0051, -0.0004,  0.0012])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0051,  0.0000,  0.0004,  0.0036, -0.0032])\n",
      "0.4635 mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([ 0.0102,  0.0000,  0.0030, -0.0016,  0.0038])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0053,  0.0000, -0.0015,  0.0002, -0.0054])\n",
      "mean grad:\n",
      " tensor(-0.0026) \n",
      " first 5 grad tensor([ 0.0081,  0.0000, -0.0082, -0.0120, -0.0060])\n",
      "mean grad:\n",
      " tensor(0.0017) \n",
      " first 5 grad tensor([0.0038, 0.0000, 0.0052, 0.0014, 0.0027])\n",
      "mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([-0.0020,  0.0000,  0.0037, -0.0018, -0.0010])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([ 0.0046,  0.0000,  0.0023, -0.0029,  0.0112])\n",
      "mean grad:\n",
      " tensor(-0.0001) \n",
      " first 5 grad tensor([-3.2407e-03,  0.0000e+00,  7.5743e-05, -2.1331e-03,  2.4508e-03])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([-0.0016,  0.0000, -0.0070,  0.0008, -0.0010])\n",
      "mean grad:\n",
      " tensor(-0.0007) \n",
      " first 5 grad tensor([ 0.0037,  0.0000, -0.0055,  0.0029, -0.0019])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0110,  0.0000, -0.0033,  0.0070,  0.0050])\n",
      "mean grad:\n",
      " tensor(0.0011) \n",
      " first 5 grad tensor([ 0.0051,  0.0000,  0.0059, -0.0011,  0.0004])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([ 0.0043,  0.0000, -0.0004,  0.0023, -0.0046])\n",
      "0.4635 mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([8.4927e-03, 0.0000e+00, 6.3430e-04, 5.1016e-05, 2.3198e-03])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0053,  0.0000, -0.0014, -0.0009, -0.0057])\n",
      "mean grad:\n",
      " tensor(-0.0022) \n",
      " first 5 grad tensor([ 0.0071,  0.0000, -0.0081, -0.0118, -0.0062])\n",
      "mean grad:\n",
      " tensor(0.0014) \n",
      " first 5 grad tensor([0.0045, 0.0000, 0.0044, 0.0019, 0.0029])\n",
      "mean grad:\n",
      " tensor(0.0005) \n",
      " first 5 grad tensor([-0.0016,  0.0000,  0.0032, -0.0010,  0.0003])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([ 0.0045,  0.0000,  0.0017, -0.0013,  0.0099])\n",
      "mean grad:\n",
      " tensor(-0.0001) \n",
      " first 5 grad tensor([-0.0036,  0.0000,  0.0002, -0.0026,  0.0027])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([-0.0011,  0.0000, -0.0066,  0.0009, -0.0003])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0047,  0.0000, -0.0053,  0.0043, -0.0008])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([ 0.0104,  0.0000, -0.0033,  0.0073,  0.0056])\n",
      "mean grad:\n",
      " tensor(0.0011) \n",
      " first 5 grad tensor([ 0.0078,  0.0000,  0.0066, -0.0019, -0.0003])\n",
      "mean grad:\n",
      " tensor(-0.0008) \n",
      " first 5 grad tensor([ 0.0038,  0.0000, -0.0011,  0.0014, -0.0056])\n",
      "0.4634 mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([ 0.0069,  0.0000, -0.0005,  0.0013,  0.0011])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0052,  0.0000, -0.0011, -0.0017, -0.0057])\n",
      "mean grad:\n",
      " tensor(-0.0018) \n",
      " first 5 grad tensor([ 0.0063,  0.0000, -0.0083, -0.0109, -0.0059])\n",
      "mean grad:\n",
      " tensor(0.0010) \n",
      " first 5 grad tensor([0.0058, 0.0000, 0.0034, 0.0027, 0.0034])\n",
      "mean grad:\n",
      " tensor(0.0005) \n",
      " first 5 grad tensor([-0.0014,  0.0000,  0.0028, -0.0004,  0.0014])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([0.0045, 0.0000, 0.0005, 0.0016, 0.0076])\n",
      "mean grad:\n",
      " tensor(-0.0001) \n",
      " first 5 grad tensor([-0.0040,  0.0000,  0.0002, -0.0030,  0.0030])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([-0.0002,  0.0000, -0.0060,  0.0009,  0.0008])\n",
      "mean grad:\n",
      " tensor(-0.0004) \n",
      " first 5 grad tensor([ 0.0053,  0.0000, -0.0052,  0.0051, -0.0002])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([ 0.0102,  0.0000, -0.0033,  0.0080,  0.0062])\n",
      "mean grad:\n",
      " tensor(0.0012) \n",
      " first 5 grad tensor([ 0.0098,  0.0000,  0.0071, -0.0023, -0.0004])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([ 0.0036,  0.0000, -0.0017,  0.0006, -0.0065])\n",
      "0.4635 mean grad:\n",
      " tensor(-0.0004) \n",
      " first 5 grad tensor([ 0.0060,  0.0000, -0.0002,  0.0017,  0.0003])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0050,  0.0000, -0.0006, -0.0021, -0.0054])\n",
      "mean grad:\n",
      " tensor(-0.0015) \n",
      " first 5 grad tensor([ 0.0057,  0.0000, -0.0087, -0.0099, -0.0055])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([0.0076, 0.0000, 0.0023, 0.0038, 0.0044])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([-1.1739e-03,  0.0000e+00,  2.4457e-03, -1.9912e-05,  2.0193e-03])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0060,  0.0000, -0.0014,  0.0037,  0.0067])\n",
      "mean grad:\n",
      " tensor(-0.0001) \n",
      " first 5 grad tensor([-0.0043,  0.0000,  0.0003, -0.0033,  0.0032])\n",
      "mean grad:\n",
      " tensor(-0.0008) \n",
      " first 5 grad tensor([ 0.0012,  0.0000, -0.0047,  0.0009,  0.0025])\n",
      "mean grad:\n",
      " tensor(-0.0004) \n",
      " first 5 grad tensor([ 0.0056,  0.0000, -0.0049,  0.0055,  0.0001])\n",
      "mean grad:\n",
      " tensor(-2.5668e-05) \n",
      " first 5 grad tensor([ 0.0106,  0.0000, -0.0032,  0.0089,  0.0067])\n",
      "mean grad:\n",
      " tensor(0.0012) \n",
      " first 5 grad tensor([ 0.0115,  0.0000,  0.0078, -0.0027,  0.0001])\n",
      "mean grad:\n",
      " tensor(-0.0011) \n",
      " first 5 grad tensor([ 0.0035,  0.0000, -0.0023, -0.0001, -0.0073])\n",
      "0.4635 mean grad:\n",
      " tensor(-0.0001) \n",
      " first 5 grad tensor([ 0.0055,  0.0000,  0.0006,  0.0017, -0.0004])\n",
      "mean grad:\n",
      " tensor(-0.0004) \n",
      " first 5 grad tensor([ 4.8071e-03,  0.0000e+00, -4.5133e-05, -2.0964e-03, -4.7162e-03])\n",
      "mean grad:\n",
      " tensor(-0.0013) \n",
      " first 5 grad tensor([ 0.0049,  0.0000, -0.0086, -0.0089, -0.0050])\n",
      "mean grad:\n",
      " tensor(0.0003) \n",
      " first 5 grad tensor([0.0097, 0.0000, 0.0017, 0.0049, 0.0054])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([-0.0010,  0.0000,  0.0021,  0.0003,  0.0023])\n",
      "mean grad:\n",
      " tensor(-0.0011) \n",
      " first 5 grad tensor([ 0.0090,  0.0000, -0.0043,  0.0053,  0.0065])\n",
      "mean grad:\n",
      " tensor(-0.0001) \n",
      " first 5 grad tensor([-0.0047,  0.0000,  0.0003, -0.0036,  0.0034])\n",
      "mean grad:\n",
      " tensor(-0.0007) \n",
      " first 5 grad tensor([ 0.0036,  0.0000, -0.0026,  0.0009,  0.0053])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([ 0.0054,  0.0000, -0.0042,  0.0054,  0.0002])\n",
      "mean grad:\n",
      " tensor(7.4304e-05) \n",
      " first 5 grad tensor([ 0.0114,  0.0000, -0.0029,  0.0100,  0.0070])\n",
      "mean grad:\n",
      " tensor(0.0013) \n",
      " first 5 grad tensor([ 0.0135,  0.0000,  0.0089, -0.0034,  0.0007])\n",
      "mean grad:\n",
      " tensor(-0.0012) \n",
      " first 5 grad tensor([ 0.0033,  0.0000, -0.0027, -0.0007, -0.0076])\n",
      "0.474 mean grad:\n",
      " tensor(6.9103e-05) \n",
      " first 5 grad tensor([ 0.0052,  0.0000,  0.0013,  0.0016, -0.0009])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([ 0.0051,  0.0000,  0.0001, -0.0018, -0.0042])\n",
      "mean grad:\n",
      " tensor(-0.0010) \n",
      " first 5 grad tensor([ 0.0039,  0.0000, -0.0078, -0.0080, -0.0045])\n",
      "mean grad:\n",
      " tensor(0.0003) \n",
      " first 5 grad tensor([0.0101, 0.0000, 0.0021, 0.0050, 0.0052])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([-0.0010,  0.0000,  0.0018,  0.0004,  0.0021])\n",
      "mean grad:\n",
      " tensor(-0.0018) \n",
      " first 5 grad tensor([ 0.0118,  0.0000, -0.0071,  0.0064,  0.0068])\n",
      "mean grad:\n",
      " tensor(-0.0001) \n",
      " first 5 grad tensor([-0.0052,  0.0000,  0.0003, -0.0039,  0.0034])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([ 0.0060,  0.0000, -0.0009,  0.0013,  0.0077])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([ 0.0051,  0.0000, -0.0031,  0.0050,  0.0001])\n",
      "mean grad:\n",
      " tensor(0.0001) \n",
      " first 5 grad tensor([ 0.0125,  0.0000, -0.0019,  0.0111,  0.0070])\n",
      "mean grad:\n",
      " tensor(0.0014) \n",
      " first 5 grad tensor([ 0.0144,  0.0000,  0.0099, -0.0042,  0.0010])\n",
      "mean grad:\n",
      " tensor(-0.0012) \n",
      " first 5 grad tensor([ 0.0030,  0.0000, -0.0028, -0.0010, -0.0076])\n",
      "0.4795 mean grad:\n",
      " tensor(0.0002) \n",
      " first 5 grad tensor([ 0.0044,  0.0000,  0.0010,  0.0017, -0.0007])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([ 0.0060,  0.0000, -0.0002, -0.0016, -0.0040])\n",
      "mean grad:\n",
      " tensor(-0.0008) \n",
      " first 5 grad tensor([ 0.0028,  0.0000, -0.0066, -0.0073, -0.0039])\n",
      "mean grad:\n",
      " tensor(0.0005) \n",
      " first 5 grad tensor([0.0078, 0.0000, 0.0025, 0.0038, 0.0032])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([-0.0011,  0.0000,  0.0015,  0.0002,  0.0014])\n",
      "mean grad:\n",
      " tensor(-0.0019) \n",
      " first 5 grad tensor([ 0.0118,  0.0000, -0.0084,  0.0066,  0.0069])\n",
      "mean grad:\n",
      " tensor(-0.0001) \n",
      " first 5 grad tensor([-0.0056,  0.0000,  0.0003, -0.0042,  0.0033])\n",
      "mean grad:\n",
      " tensor(-0.0007) \n",
      " first 5 grad tensor([ 0.0065,  0.0000, -0.0012,  0.0026,  0.0074])\n",
      "mean grad:\n",
      " tensor(-0.0001) \n",
      " first 5 grad tensor([ 4.9038e-03,  0.0000e+00, -1.4840e-03,  4.5856e-03, -3.3367e-05])\n",
      "mean grad:\n",
      " tensor(0.0002) \n",
      " first 5 grad tensor([0.0137, 0.0000, 0.0002, 0.0118, 0.0068])\n",
      "mean grad:\n",
      " tensor(0.0013) \n",
      " first 5 grad tensor([ 0.0094,  0.0000,  0.0088, -0.0027,  0.0016])\n",
      "mean grad:\n",
      " tensor(-0.0011) \n",
      " first 5 grad tensor([ 0.0027,  0.0000, -0.0028, -0.0010, -0.0072])\n",
      "0.4795 mean grad:\n",
      " tensor(0.0002) \n",
      " first 5 grad tensor([ 0.0039,  0.0000,  0.0006,  0.0017, -0.0003])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([ 0.0064,  0.0000, -0.0006, -0.0019, -0.0039])\n",
      "mean grad:\n",
      " tensor(-0.0007) \n",
      " first 5 grad tensor([ 0.0020,  0.0000, -0.0058, -0.0069, -0.0035])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([0.0060, 0.0000, 0.0026, 0.0030, 0.0017])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([-1.1531e-03,  0.0000e+00,  1.2887e-03,  7.1765e-06,  6.4721e-04])\n",
      "mean grad:\n",
      " tensor(-0.0018) \n",
      " first 5 grad tensor([ 0.0103,  0.0000, -0.0084,  0.0063,  0.0070])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([-0.0059,  0.0000,  0.0003, -0.0046,  0.0030])\n",
      "mean grad:\n",
      " tensor(-0.0008) \n",
      " first 5 grad tensor([ 0.0070,  0.0000, -0.0019,  0.0047,  0.0067])\n",
      "mean grad:\n",
      " tensor(-2.8081e-05) \n",
      " first 5 grad tensor([ 0.0050,  0.0000,  0.0007,  0.0044, -0.0003])\n",
      "mean grad:\n",
      " tensor(0.0002) \n",
      " first 5 grad tensor([0.0150, 0.0000, 0.0031, 0.0118, 0.0064])\n",
      "mean grad:\n",
      " tensor(0.0013) \n",
      " first 5 grad tensor([ 0.0040,  0.0000,  0.0072, -0.0010,  0.0021])\n",
      "mean grad:\n",
      " tensor(-0.0011) \n",
      " first 5 grad tensor([ 0.0025,  0.0000, -0.0027, -0.0011, -0.0068])\n",
      "0.4795 mean grad:\n",
      " tensor(0.0003) \n",
      " first 5 grad tensor([4.2083e-03, 0.0000e+00, 8.1593e-04, 1.3926e-03, 2.2688e-05])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([ 0.0055,  0.0000, -0.0011, -0.0023, -0.0042])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([ 0.0015,  0.0000, -0.0056, -0.0068, -0.0034])\n",
      "mean grad:\n",
      " tensor(0.0008) \n",
      " first 5 grad tensor([0.0052, 0.0000, 0.0027, 0.0029, 0.0007])\n",
      "mean grad:\n",
      " tensor(0.0005) \n",
      " first 5 grad tensor([-0.0012,  0.0000,  0.0011, -0.0003, -0.0002])\n",
      "mean grad:\n",
      " tensor(-0.0016) \n",
      " first 5 grad tensor([ 0.0089,  0.0000, -0.0080,  0.0057,  0.0069])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([-0.0062,  0.0000,  0.0004, -0.0050,  0.0024])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([ 0.0087,  0.0000, -0.0017,  0.0074,  0.0070])\n",
      "mean grad:\n",
      " tensor(0.0001) \n",
      " first 5 grad tensor([ 0.0059,  0.0000,  0.0035,  0.0041, -0.0003])\n",
      "mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([0.0160, 0.0000, 0.0047, 0.0098, 0.0050])\n",
      "mean grad:\n",
      " tensor(0.0012) \n",
      " first 5 grad tensor([ 0.0023,  0.0000,  0.0067, -0.0004,  0.0022])\n",
      "mean grad:\n",
      " tensor(-0.0010) \n",
      " first 5 grad tensor([ 0.0023,  0.0000, -0.0027, -0.0011, -0.0065])\n",
      "0.4793 mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([0.0056, 0.0000, 0.0017, 0.0008, 0.0003])\n",
      "mean grad:\n",
      " tensor(-0.0004) \n",
      " first 5 grad tensor([ 0.0028,  0.0000, -0.0021, -0.0024, -0.0053])\n",
      "mean grad:\n",
      " tensor(-0.0007) \n",
      " first 5 grad tensor([ 0.0013,  0.0000, -0.0058, -0.0069, -0.0035])\n",
      "mean grad:\n",
      " tensor(0.0009) \n",
      " first 5 grad tensor([0.0049, 0.0000, 0.0029, 0.0033, 0.0002])\n",
      "mean grad:\n",
      " tensor(0.0005) \n",
      " first 5 grad tensor([-0.0013,  0.0000,  0.0009, -0.0005, -0.0010])\n",
      "mean grad:\n",
      " tensor(-0.0014) \n",
      " first 5 grad tensor([ 0.0079,  0.0000, -0.0070,  0.0051,  0.0066])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([-0.0064,  0.0000,  0.0006, -0.0054,  0.0015])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([ 0.0092,  0.0000, -0.0016,  0.0086,  0.0067])\n",
      "mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([0.0071, 0.0000, 0.0060, 0.0027, 0.0004])\n",
      "mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([0.0160, 0.0000, 0.0032, 0.0069, 0.0033])\n",
      "mean grad:\n",
      " tensor(0.0013) \n",
      " first 5 grad tensor([ 0.0038,  0.0000,  0.0071, -0.0004,  0.0023])\n",
      "mean grad:\n",
      " tensor(-0.0010) \n",
      " first 5 grad tensor([ 0.0022,  0.0000, -0.0026, -0.0011, -0.0063])\n",
      "0.4899 mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([0.0071, 0.0000, 0.0026, 0.0002, 0.0004])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0003,  0.0000, -0.0029, -0.0025, -0.0063])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([ 0.0013,  0.0000, -0.0062, -0.0070, -0.0037])\n",
      "mean grad:\n",
      " tensor(0.0009) \n",
      " first 5 grad tensor([ 0.0049,  0.0000,  0.0030,  0.0040, -0.0002])\n",
      "mean grad:\n",
      " tensor(0.0005) \n",
      " first 5 grad tensor([-0.0013,  0.0000,  0.0008, -0.0006, -0.0015])\n",
      "mean grad:\n",
      " tensor(-0.0012) \n",
      " first 5 grad tensor([ 0.0072,  0.0000, -0.0060,  0.0048,  0.0063])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([-0.0063,  0.0000,  0.0005, -0.0055,  0.0009])\n",
      "mean grad:\n",
      " tensor(-0.0008) \n",
      " first 5 grad tensor([ 0.0064,  0.0000, -0.0025,  0.0071,  0.0048])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([0.0071, 0.0000, 0.0067, 0.0012, 0.0010])\n",
      "mean grad:\n",
      " tensor(0.0003) \n",
      " first 5 grad tensor([1.3542e-02, 0.0000e+00, 6.2076e-05, 6.3995e-03, 3.3540e-03])\n",
      "mean grad:\n",
      " tensor(0.0013) \n",
      " first 5 grad tensor([ 0.0062,  0.0000,  0.0074, -0.0006,  0.0021])\n",
      "mean grad:\n",
      " tensor(-0.0010) \n",
      " first 5 grad tensor([ 0.0022,  0.0000, -0.0026, -0.0011, -0.0061])\n",
      "0.4899 mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([0.0074, 0.0000, 0.0029, 0.0001, 0.0005])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([-0.0009,  0.0000, -0.0032, -0.0026, -0.0066])\n",
      "mean grad:\n",
      " tensor(-0.0010) \n",
      " first 5 grad tensor([ 0.0013,  0.0000, -0.0064, -0.0068, -0.0037])\n",
      "mean grad:\n",
      " tensor(0.0010) \n",
      " first 5 grad tensor([ 0.0049,  0.0000,  0.0031,  0.0048, -0.0003])\n",
      "mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([-0.0013,  0.0000,  0.0007, -0.0006, -0.0017])\n",
      "mean grad:\n",
      " tensor(-0.0010) \n",
      " first 5 grad tensor([ 0.0064,  0.0000, -0.0049,  0.0044,  0.0061])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([-0.0059,  0.0000,  0.0004, -0.0053,  0.0008])\n",
      "mean grad:\n",
      " tensor(-0.0007) \n",
      " first 5 grad tensor([ 0.0036,  0.0000, -0.0031,  0.0053,  0.0033])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([0.0055, 0.0000, 0.0057, 0.0007, 0.0009])\n",
      "mean grad:\n",
      " tensor(0.0001) \n",
      " first 5 grad tensor([ 0.0113,  0.0000, -0.0018,  0.0065,  0.0037])\n",
      "mean grad:\n",
      " tensor(0.0014) \n",
      " first 5 grad tensor([ 0.0080,  0.0000,  0.0075, -0.0008,  0.0015])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([ 0.0020,  0.0000, -0.0025, -0.0011, -0.0058])\n",
      "0.4953 mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([0.0069, 0.0000, 0.0028, 0.0004, 0.0006])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([-0.0015,  0.0000, -0.0031, -0.0026, -0.0064])\n",
      "mean grad:\n",
      " tensor(-0.0010) \n",
      " first 5 grad tensor([ 0.0012,  0.0000, -0.0064, -0.0065, -0.0034])\n",
      "mean grad:\n",
      " tensor(0.0009) \n",
      " first 5 grad tensor([ 0.0048,  0.0000,  0.0031,  0.0055, -0.0003])\n",
      "mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([-0.0012,  0.0000,  0.0007, -0.0005, -0.0018])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([ 0.0055,  0.0000, -0.0039,  0.0038,  0.0059])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([-0.0055,  0.0000,  0.0003, -0.0050,  0.0008])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([ 0.0019,  0.0000, -0.0034,  0.0041,  0.0024])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([0.0040, 0.0000, 0.0047, 0.0004, 0.0007])\n",
      "mean grad:\n",
      " tensor(9.9448e-05) \n",
      " first 5 grad tensor([ 0.0098,  0.0000, -0.0025,  0.0063,  0.0038])\n",
      "mean grad:\n",
      " tensor(0.0013) \n",
      " first 5 grad tensor([ 0.0091,  0.0000,  0.0074, -0.0011,  0.0008])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([ 0.0018,  0.0000, -0.0024, -0.0012, -0.0053])\n",
      "0.4953 mean grad:\n",
      " tensor(0.0005) \n",
      " first 5 grad tensor([0.0063, 0.0000, 0.0025, 0.0007, 0.0007])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([-0.0019,  0.0000, -0.0030, -0.0024, -0.0061])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([ 0.0011,  0.0000, -0.0063, -0.0062, -0.0031])\n",
      "mean grad:\n",
      " tensor(0.0009) \n",
      " first 5 grad tensor([ 0.0046,  0.0000,  0.0031,  0.0060, -0.0001])\n",
      "mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([-0.0012,  0.0000,  0.0006, -0.0005, -0.0018])\n",
      "mean grad:\n",
      " tensor(-0.0007) \n",
      " first 5 grad tensor([ 0.0046,  0.0000, -0.0029,  0.0032,  0.0057])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([-0.0052,  0.0000,  0.0002, -0.0048,  0.0009])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0009,  0.0000, -0.0035,  0.0034,  0.0020])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([0.0029, 0.0000, 0.0041, 0.0003, 0.0006])\n",
      "mean grad:\n",
      " tensor(8.7991e-05) \n",
      " first 5 grad tensor([ 0.0087,  0.0000, -0.0028,  0.0059,  0.0037])\n",
      "mean grad:\n",
      " tensor(0.0013) \n",
      " first 5 grad tensor([ 9.7889e-03,  0.0000e+00,  7.1072e-03, -1.5113e-03, -4.3563e-05])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([ 0.0017,  0.0000, -0.0022, -0.0012, -0.0048])\n",
      "0.5005 mean grad:\n",
      " tensor(0.0005) \n",
      " first 5 grad tensor([0.0057, 0.0000, 0.0023, 0.0011, 0.0007])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([-0.0022,  0.0000, -0.0027, -0.0022, -0.0057])\n",
      "mean grad:\n",
      " tensor(-0.0008) \n",
      " first 5 grad tensor([ 0.0010,  0.0000, -0.0062, -0.0059, -0.0029])\n",
      "mean grad:\n",
      " tensor(0.0008) \n",
      " first 5 grad tensor([4.1762e-03, 0.0000e+00, 2.9375e-03, 6.4577e-03, 9.2912e-05])\n",
      "mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([-0.0011,  0.0000,  0.0006, -0.0004, -0.0018])\n",
      "mean grad:\n",
      " tensor(-0.0005) \n",
      " first 5 grad tensor([ 0.0038,  0.0000, -0.0020,  0.0026,  0.0055])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([-0.0049,  0.0000,  0.0002, -0.0047,  0.0010])\n",
      "mean grad:\n",
      " tensor(-0.0004) \n",
      " first 5 grad tensor([ 0.0002,  0.0000, -0.0034,  0.0029,  0.0017])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([0.0021, 0.0000, 0.0037, 0.0001, 0.0005])\n",
      "mean grad:\n",
      " tensor(9.1317e-05) \n",
      " first 5 grad tensor([ 0.0077,  0.0000, -0.0028,  0.0055,  0.0036])\n",
      "mean grad:\n",
      " tensor(0.0012) \n",
      " first 5 grad tensor([ 0.0100,  0.0000,  0.0067, -0.0019, -0.0008])\n",
      "mean grad:\n",
      " tensor(-0.0008) \n",
      " first 5 grad tensor([ 0.0015,  0.0000, -0.0021, -0.0013, -0.0043])\n",
      "0.5057 mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([0.0052, 0.0000, 0.0022, 0.0013, 0.0008])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([-0.0024,  0.0000, -0.0025, -0.0020, -0.0054])\n",
      "mean grad:\n",
      " tensor(-0.0008) \n",
      " first 5 grad tensor([ 0.0010,  0.0000, -0.0061, -0.0056, -0.0026])\n",
      "mean grad:\n",
      " tensor(0.0008) \n",
      " first 5 grad tensor([0.0038, 0.0000, 0.0028, 0.0068, 0.0004])\n",
      "mean grad:\n",
      " tensor(0.0003) \n",
      " first 5 grad tensor([-0.0010,  0.0000,  0.0005, -0.0004, -0.0018])\n",
      "mean grad:\n",
      " tensor(-0.0004) \n",
      " first 5 grad tensor([ 0.0031,  0.0000, -0.0012,  0.0020,  0.0054])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([-0.0046,  0.0000,  0.0002, -0.0046,  0.0011])\n",
      "mean grad:\n",
      " tensor(-0.0004) \n",
      " first 5 grad tensor([-0.0003,  0.0000, -0.0034,  0.0026,  0.0016])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([1.4264e-03, 0.0000e+00, 3.4486e-03, 3.1149e-05, 3.8946e-04])\n",
      "mean grad:\n",
      " tensor(0.0001) \n",
      " first 5 grad tensor([ 0.0069,  0.0000, -0.0028,  0.0051,  0.0034])\n",
      "mean grad:\n",
      " tensor(0.0012) \n",
      " first 5 grad tensor([ 0.0098,  0.0000,  0.0063, -0.0021, -0.0013])\n",
      "mean grad:\n",
      " tensor(-0.0007) \n",
      " first 5 grad tensor([ 0.0013,  0.0000, -0.0020, -0.0014, -0.0038])\n",
      "0.5161 mean grad:\n",
      " tensor(0.0004) \n",
      " first 5 grad tensor([0.0049, 0.0000, 0.0021, 0.0016, 0.0008])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([-0.0026,  0.0000, -0.0023, -0.0018, -0.0050])\n",
      "mean grad:\n",
      " tensor(-0.0007) \n",
      " first 5 grad tensor([ 0.0009,  0.0000, -0.0060, -0.0053, -0.0024])\n",
      "mean grad:\n",
      " tensor(0.0007) \n",
      " first 5 grad tensor([0.0033, 0.0000, 0.0026, 0.0072, 0.0006])\n",
      "mean grad:\n",
      " tensor(0.0003) \n",
      " first 5 grad tensor([-0.0009,  0.0000,  0.0005, -0.0003, -0.0017])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([ 0.0025,  0.0000, -0.0005,  0.0016,  0.0053])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([-0.0044,  0.0000,  0.0002, -0.0045,  0.0012])\n",
      "mean grad:\n",
      " tensor(-0.0003) \n",
      " first 5 grad tensor([-0.0006,  0.0000, -0.0033,  0.0023,  0.0015])\n",
      "mean grad:\n",
      " tensor(0.0006) \n",
      " first 5 grad tensor([ 9.4691e-04,  0.0000e+00,  3.2714e-03, -6.3030e-05,  3.1624e-04])\n",
      "mean grad:\n",
      " tensor(0.0001) \n",
      " first 5 grad tensor([ 0.0063,  0.0000, -0.0028,  0.0048,  0.0033])\n",
      "mean grad:\n",
      " tensor(0.0011) \n",
      " first 5 grad tensor([ 0.0089,  0.0000,  0.0058, -0.0020, -0.0015])\n",
      "mean grad:\n",
      " tensor(-0.0007) \n",
      " first 5 grad tensor([ 0.0011,  0.0000, -0.0019, -0.0015, -0.0033])\n",
      "0.5213 percent change in weights:\n",
      " tensor([-0.0935,  0.0000,  0.0077, -0.0104, -0.0110]) \n",
      " first init weights:\n",
      " tensor([-0.3243,  0.9756,  0.8768, -0.6417,  0.9659]) \n",
      " first end weights:\n",
      " tensor([-0.4177,  0.9756,  0.8846, -0.6521,  0.9550])\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    #save initail weights and bias\n",
    "    if i == 0:\n",
    "        init_weights = weights_1.clone().detach()\n",
    "        init_bias = bias_1.clone().detach()\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')\n",
    "    #save ends weights and bias\n",
    "    if i == 19:\n",
    "        end_weights = weights_1.clone().detach()\n",
    "        end_bias = bias_1.clone().detach()\n",
    "        #calc percent change in weights and bias\n",
    "        print('percent change in weights:\\n', ((end_weights[:5] - init_weights[:5])),\n",
    "              '\\n first init weights:\\n', init_weights[:5],\n",
    "                '\\n first end weights:\\n', end_weights[:5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:20:23.873071257Z",
     "start_time": "2023-11-29T08:20:23.855436864Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#manual training\n",
    "lr = 0.5\n",
    "params = weights_1, bias_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:19:11.307848016Z",
     "start_time": "2023-11-29T08:19:11.207585312Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean grad:\n",
      " tensor(-3.1388e-05) \n",
      " first 5 grad tensor([ 0.0102,  0.0000,  0.0042, -0.0033,  0.0039])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([-0.0047,  0.0000, -0.0034, -0.0021,  0.0017])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([ 0.0017,  0.0000,  0.0041, -0.0127, -0.0035])\n",
      "mean grad:\n",
      " tensor(-0.0002) \n",
      " first 5 grad tensor([ 0.0049,  0.0000,  0.0049, -0.0081, -0.0131])\n",
      "mean grad:\n",
      " tensor(0.0003) \n",
      " first 5 grad tensor([-0.0019,  0.0000,  0.0001, -0.0065, -0.0056])\n",
      "mean grad:\n",
      " tensor(-0.0009) \n",
      " first 5 grad tensor([ 0.0009,  0.0000, -0.0061,  0.0024,  0.0066])\n",
      "mean grad:\n",
      " tensor(0.0003) \n",
      " first 5 grad tensor([ 0.0002,  0.0000,  0.0005, -0.0004,  0.0006])\n",
      "mean grad:\n",
      " tensor(-0.0012) \n",
      " first 5 grad tensor([-0.0030,  0.0000, -0.0097, -0.0068,  0.0012])\n",
      "mean grad:\n",
      " tensor(-0.0012) \n",
      " first 5 grad tensor([-0.0012,  0.0000, -0.0054,  0.0025,  0.0050])\n",
      "mean grad:\n",
      " tensor(0.0002) \n",
      " first 5 grad tensor([ 0.0168,  0.0000, -0.0071,  0.0074,  0.0073])\n",
      "mean grad:\n",
      " tensor(-0.0006) \n",
      " first 5 grad tensor([ 0.0159,  0.0000, -0.0043,  0.0054,  0.0005])\n",
      "mean grad:\n",
      " tensor(0.0008) \n",
      " first 5 grad tensor([ 0.0033,  0.0000,  0.0055,  0.0029, -0.0031])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4153"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:21:38.184800245Z",
     "start_time": "2023-11-29T08:21:38.127987588Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a simple neural network\n",
    "\n",
    "# input size is 512\n",
    "nn_model = nn.Sequential(\n",
    "    nn.Linear(855, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T13:46:15.618648730Z",
     "start_time": "2023-11-28T13:46:15.423282180Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 512]), torch.Size([256]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b = nn_model[0].parameters()\n",
    "w.shape,b.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:21:42.953943622Z",
     "start_time": "2023-11-29T08:21:42.913116929Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#having creted dataloadrs from data sets for train and cal, create a dls \n",
    "dls = DataLoaders(dl_train, dl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:21:45.542063044Z",
     "start_time": "2023-11-29T08:21:45.522877628Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create your learner\n",
    "learn = Learner(dls, nn_model, opt_func = SGD, loss_func=stamp_loss, metrics=error_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:21:57.452468249Z",
     "start_time": "2023-11-29T08:21:55.692920475Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=1.5848931980144698e-06)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find lr\n",
    "learn.lr_find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T13:46:17.119022493Z",
     "start_time": "2023-11-28T13:46:17.117936678Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=1.5848931980144698e-06)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man_lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:22:09.845161014Z",
     "start_time": "2023-11-29T08:22:08.501866552Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.528741</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.512637</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.507372</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.504816</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.503340</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.502402</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.501769</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.501324</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.501003</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.500766</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T08:22:23.558207687Z",
     "start_time": "2023-11-29T08:22:23.547218910Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assuming 'learn' is your Learner object and you have 'accuracy' as one of the metrics\n",
    "last_epoch_metrics = learn.recorder.metrics[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T11:15:58.852931Z",
     "start_time": "2023-11-24T11:15:58.542507800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess the data (Assuming 'label' is your target variable)\n",
    "X = data .drop(['oncosig_label_ERBB2', 'Sample_ID'], axis=1)\n",
    "y = data ['oncosig_label_ERBB2']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T11:17:33.671676200Z",
     "start_time": "2023-11-24T11:17:05.530515800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       166\n",
      "           1       0.92      0.50      0.65        24\n",
      "\n",
      "    accuracy                           0.93       190\n",
      "   macro avg       0.93      0.75      0.81       190\n",
      "weighted avg       0.93      0.93      0.92       190\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Evaluation for Random Forest\n",
    "rf_predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "sns.heatmap(confusion_matrix(y_test, rf_predictions), annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T11:18:07.261974200Z",
     "start_time": "2023-11-24T11:18:06.469657300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesse\\Google Drive\\Learning\\shair lab\\STAMP\\laptop_venvs\\gene_map_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jesse\\Google Drive\\Learning\\shair lab\\STAMP\\laptop_venvs\\gene_map_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jesse\\Google Drive\\Learning\\shair lab\\STAMP\\laptop_venvs\\gene_map_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       166\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.87       190\n",
      "   macro avg       0.44      0.50      0.47       190\n",
      "weighted avg       0.76      0.87      0.81       190\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Train Elastic Net\n",
    "en = ElasticNet()\n",
    "en.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Evaluation for Elastic Net\n",
    "# Note: Elastic Net is a regression model; you might need to convert its predictions to a binary format for classification\n",
    "en_predictions = en.predict(X_test)\n",
    "en_predictions = [1 if p > 0.5 else 0 for p in en_predictions]  # Example threshold\n",
    "print(classification_report(y_test, en_predictions))\n",
    "sns.heatmap(confusion_matrix(y_test, en_predictions), annot=True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
